%!TEX root=seke.tex
% mainfile: seke.tex

\documentclass[times,10pt,twocolumn]{article}
\usepackage{latex8}
\usepackage{times}
\usepackage{pifont}

\usepackage[numbers]{natbib}
\usepackage{graphicx}
\usepackage{algorithm}
\usepackage{algorithmic}

\usepackage{tikz}
\usetikzlibrary{shapes,arrows,shadows}
\usepackage{amsmath,bm,times}
\usepackage{verbatim}

\newcommand{\goallegheny}{$^{\mbox{\footnotesize \ding{72}}}$}
\newcommand{\gosheffield}{$^{\mbox{\footnotesize \ding{73}}}$}
\newcommand{\gospace}{$\;$}

\begin{document}

\title{Empirically Evaluating the Efficiency of Search-based \\ Test Data
Generation for Relational Database Schemas\vspace*{-.1in}}

\author{Cody Kinneer \goallegheny                \and
        Gregory M.\ Kapfhammer \goallegheny      \and
        Chris Wright \gosheffield                \and
        Phil McMinn \gosheffield \vspace*{-.1in}
      }

\affiliation{
      \goallegheny \gospace Allegheny College       \and
      \gosheffield \gospace University of Sheffield
}

\maketitle

\begin{abstract}

% When evaluating an algorithm, it is often useful to speak of it's efficiency in terms of it's worst-case complexity.
% This is the case for search-based test data generation tools.
% on the search-based data generation tool \textit{SchemaAnalyst}.

The characterization of an algorithm's worst-case time complexity is useful because it succinctly captures how algorithm
runtime will grow as the input size becomes arbitrarily large.  However, for certain algorithms --- such as search-based
test data generation --- a theoretical analysis to determine worst-case complexity is difficult and thus not reported in
the literature.  This paper introduces a framework for conducting automated empirical studies of algorithms by doubling
the size of the input and observing the change in runtime.  After describing a technique for systematically doubling the
size of structured data, we report on a study demonstrating the effectiveness of the presented method.  Since the
relational database is a centerpiece of modern software and the database's schema is frequently untested, we apply the
doubling technique to the domain of data generation for relational database schemas. In addition to revealing that it is
possible to accurately pinpoint the worst-case time complexity of the chosen data generators, the results of our study
reveal fundamental performance trade-offs in schema testing strategies.

\end{abstract}

\input{../writing/intro}
\input{../writing/background}
\input{../writing/technique}
\input{../writing/experimentdesign}
\input{../writing/results}
%\input{../writing/relatedworks}
%\input{../writing/conclusion}

\bibliographystyle{IEEEtran}
\bibliography{seke.bib}

\end{document}
